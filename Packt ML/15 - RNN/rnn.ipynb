{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "### Computing Activations and Outputs in RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import platform as pl \n",
    "\n",
    "use_GPU = True\n",
    "\n",
    "if use_GPU:\n",
    "    if pl.system().lower() == \"linux\":\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, batch_first=True, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: torch.Size([2, 5])\n",
      "W_hh shape: torch.Size([2, 2])\n",
      "B_xh shape: torch.Size([2])\n",
      "B_hh shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# extract the recurrence layers (layers with weights)\n",
    "w_xh = rnn_layer.weight_ih_l0 \n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n",
    "print(f\"W_xh shape: {w_xh.shape}\")\n",
    "print(f\"W_hh shape: {w_hh.shape}\")\n",
    "print(f\"B_xh shape: {b_xh.shape}\")\n",
    "print(f\"B_hh shape: {b_hh.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually call forward pass on a single layer `rnn_layer` and compute outputs at each time step  $o^{(0)},o^{(1)},o^{(2)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_seq shape: torch.Size([3, 5])\n",
      "Time step 0 =>\n",
      "\tInput = [[1. 1. 1. 1. 1.]]\n",
      "\tHidden = [[-0.4701929   0.58639044]]\n",
      "\tOutput (manual) = [[-0.3519801   0.52525216]]\n",
      "\tRNN Output = [[-0.35198015  0.52525216]]\n",
      "Time step 1 =>\n",
      "\tInput = [[2. 2. 2. 2. 2.]]\n",
      "\tHidden = [[-0.88883156  1.2364398 ]]\n",
      "\tOutput (manual) = [[-0.68424344  0.76074266]]\n",
      "\tRNN Output = [[-0.68424344  0.76074266]]\n",
      "Time step 2 =>\n",
      "\tInput = [[3. 3. 3. 3. 3.]]\n",
      "\tHidden = [[-1.3074702  1.8864892]]\n",
      "\tOutput (manual) = [[-0.8649416  0.9046636]]\n",
      "\tRNN Output = [[-0.8649416   0.90466356]]\n"
     ]
    }
   ],
   "source": [
    "x_seq = torch.Tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
    "print(f\"x_seq shape: {x_seq.shape}\")\n",
    "\n",
    "# output of simple RNN\n",
    "output, hn = rnn_layer(x_seq.view(1,3,5))\n",
    "\n",
    "# manually compute the output\n",
    "out_manual = []\n",
    "for t in range(3):\n",
    "    xt = x_seq[t].reshape(1,5)\n",
    "    print(f\"Time step {t} =>\")\n",
    "    print(f\"\\tInput = {xt.numpy()}\")\n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
    "    print(f\"\\tHidden = {ht.detach().numpy()}\")\n",
    "    if t > 0:\n",
    "        prev_h = out_manual[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out_manual.append(ot)\n",
    "    print(f\"\\tOutput (manual) = {ot.detach().numpy()}\")\n",
    "    print(f\"\\tRNN Output = {output[:,t].detach().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1: Predicting Sentiment of IMDb Movie Reviews\n",
    "\n",
    "Before data is fed into the model, the following preprocessing steps are needed:\n",
    "1. Split training set into train and val\n",
    "2. Identify unique words \n",
    "3. Map unique word to unique integer and encode movie review into encoded integers\n",
    "4. Divide dataset into mini-batches as RNN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnathon/miniconda3/envs/hands_on_ml/lib/python3.8/site-packages/torch/utils/data/datapipes/utils/common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "/home/johnathon/miniconda3/envs/hands_on_ml/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "\n",
    "train_dataset = IMDB(split=\"train\")\n",
    "test_dataset = IMDB(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# 1. create the datasets\n",
    "torch.manual_seed(1)\n",
    "train_dataset, val_dataset = random_split(list(train_dataset), [20000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 69023\n"
     ]
    }
   ],
   "source": [
    "# 2. find unique tokens\n",
    "import re \n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def tokenizer(text):\n",
    "    # remove URLS\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "token_counts = Counter() # dict subclass for counting frequency of hashable items\n",
    "\n",
    "for label, line in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print(f\"Vocab size = {len(token_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 457]\n"
     ]
    }
   ],
   "source": [
    "# 3. encode each unique token into integers \n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab = vocab(ordered_dict)\n",
    "vocab.insert_token(\"<pad>\", 0)\n",
    "vocab.insert_token(\"<unk>\", 1)\n",
    "vocab.set_default_index(1)\n",
    "\n",
    "print([vocab[token] for token in [\"this\", \"is\", \"an\", \"example\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-A. define functions for token transformation\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: 1 if x == \"pos\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-B. wrap the encode and transformation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), \n",
    "                                      dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
      "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
      "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
      "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
      "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
      "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
      "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
      "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
      "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
      "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
      "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
      "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
      "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
      "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
      "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
      "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
      "            31,   189,  3506,   667,   163],\n",
      "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
      "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
      "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
      "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
      "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
      "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
      "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
      "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
      "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]], device='cuda:0')\n",
      "Labels =  tensor([1, 1], device='cuda:0')\n",
      "Batch lengths =  tensor([165,  86], device='cuda:0')\n",
      "Batch shape =  torch.Size([2, 165])\n"
     ]
    }
   ],
   "source": [
    "# see how padding works \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=2,shuffle=False, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)\n",
    "print(\"Labels = \", label_batch)\n",
    "print(\"Batch lengths = \", length_batch)\n",
    "print(\"Batch shape = \", text_batch.shape) # will see that batches all have shape equal to longest length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Idea: use finite-sized vectors to represent infinite number of real numbers.\n",
    "\n",
    "Since embeddings are learnable, salient features can be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7039, -0.8321, -0.4651],\n",
      "         [-0.3203,  2.2408,  0.5566],\n",
      "         [ 0.0946, -0.3531,  0.9124],\n",
      "         [-0.4643,  0.3046,  0.7046]],\n",
      "\n",
      "        [[-0.4643,  0.3046,  0.7046],\n",
      "         [ 0.0946, -0.3531,  0.9124],\n",
      "         [-0.3203,  2.2408,  0.5566],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=3, padding_idx=0) # 10 just means there's 10 different tokens for this toy example\n",
    "text_encoded_input = torch.LongTensor([[1,2,3,4],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building RNN Model\n",
    "\n",
    "Can either use `RNN`, `LSTM`, or `GRU` when building a recurrent neural network.\n",
    "\n",
    "NOTE: `LSTM` will output a tuple containing (1) the output features and (2) hidden states and cell states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, rnn_layer=nn.RNN):\n",
    "        super().__init__()\n",
    "        self.rnn = rnn_layer(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            hidden = hidden[0]\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[0.0774],\n",
      "        [0.0780],\n",
      "        [0.0749],\n",
      "        [0.0779],\n",
      "        [0.0865]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size=64, hidden_size=32, rnn_layer=nn.LSTM)\n",
    "print(model)\n",
    "print(model(torch.randn((5, 3, 64))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a RNN for Sentiment Analysis Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, output_size, rnn_layer=nn.RNN):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = rnn_layer(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), \n",
    "                                                    enforce_sorted=False, batch_first=True)\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            out, (hidden, cell) = self.rnn(out)\n",
    "        else:\n",
    "            out, hidden = self.rnn(out)\n",
    "        \n",
    "        out = hidden[-1,:,:]\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.sigmoid(self.fc2(out))\n",
    "        return out     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 69025\n",
      "RNN(\n",
      "  (embedding): Embedding(69025, 20, padding_idx=0)\n",
      "  (rnn): LSTM(20, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size = {vocab_size}\")\n",
    "\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, 1, rnn_layer=nn.LSTM)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in train_loader:\n",
    "        text_batch, label_batch = text_batch.to(device), label_batch.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:,0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(train_loader.dataset), total_loss/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    for text_batch, label_batch, lengths in val_loader:\n",
    "        text_batch, label_batch = text_batch.to(device), label_batch.to(device)\n",
    "        pred = model(text_batch, lengths)[:,0]\n",
    "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "    return total_acc/len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for e in range(num_epochs):\n",
    "    acc_train, acc_loss = train(model, train_dl, optimizer, loss_fn)\n",
    "    acc_val = evaluate(model, valid_dl)\n",
    "    print(f\"Epoch {e}/{num_epochs}: Loss = {acc_loss:.4f} | Train Acc = {acc_train:.4f} | Val Acc = {acc_val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hands_on_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c15b0dd616b9d947ea13c87fa269e05e8054758c0f7c261fec597f1be7e65f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
